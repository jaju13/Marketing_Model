{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f8a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d6332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important paths\n",
    "classification_model_folder_path = './models/Classification/'  # Folder containing all classification models which are selected\n",
    "regression_model_folder_path = './models/Regression/'  # Folder containing all classification models which are selected\n",
    "\n",
    "cleaned_data_path = './data/cleaned/data_for_modeling.pkl'  # pickle file containing cleaned data\n",
    "results_folder_path = './predicted_results/' # Folder containing predicted results\n",
    "# Column information\n",
    "\n",
    "## Columns from cleaned data that need to be removed for classification\n",
    "cols_to_drop_classification=['Sale_MF', 'Sale_CC', 'Sale_CL','Revenue_MF', \n",
    "              'Revenue_CC', 'Revenue_CL','VolumeCred_CA','TransactionsCred_CA',\n",
    "              'VolumeDeb_CA','TransactionsDeb_CA']\n",
    "\n",
    "## Columns from cleaned data that need to be removed for classification\n",
    "cols_to_drop_regression=['Sale_MF', 'Sale_CC', 'Sale_CL','Revenue_MF', 'Revenue_CC', 'Revenue_CL']\n",
    "\n",
    "## Numeric columns required to be standardized in classification\n",
    "numeric_cols_to_standardize_classification = ['Age', 'Tenure', 'Count_CA', 'Count_SA', 'Count_MF',\n",
    "       'Count_OVD', 'Count_CC', 'Count_CL', 'ActBal_CA', 'ActBal_SA',\n",
    "       'ActBal_MF', 'ActBal_OVD', 'ActBal_CC', 'ActBal_CL', 'VolumeCred',\n",
    "       'TransactionsCred', 'VolumeDeb', 'VolumeDebCash_Card', 'VolumeDebCashless_Card',\n",
    "       'VolumeDeb_PaymentOrder', 'TransactionsDeb','TransactionsDebCash_Card', 'TransactionsDebCashless_Card',\n",
    "       'TransactionsDeb_PaymentOrder']\n",
    "\n",
    "## Numeric columns required to be standardized in regression\n",
    "numeric_cols_to_standardize_regression = ['Age', 'Tenure', 'Count_CA', 'Count_SA', 'Count_MF',\n",
    "       'Count_OVD', 'Count_CC', 'Count_CL', 'ActBal_CA', 'ActBal_SA',\n",
    "       'ActBal_MF', 'ActBal_OVD', 'ActBal_CC', 'ActBal_CL', 'VolumeCred',\n",
    "       'VolumeCred_CA', 'TransactionsCred', 'TransactionsCred_CA', 'VolumeDeb',\n",
    "       'VolumeDeb_CA', 'VolumeDebCash_Card', 'VolumeDebCashless_Card',\n",
    "       'VolumeDeb_PaymentOrder', 'TransactionsDeb', 'TransactionsDeb_CA',\n",
    "       'TransactionsDebCash_Card', 'TransactionsDebCashless_Card',\n",
    "       'TransactionsDeb_PaymentOrder']\n",
    "\n",
    "## Categorical columns required to be encoded\n",
    "cat_cols_to_encode=['Sex']\n",
    "\n",
    "## Models selected for each target sale product\n",
    "model_selected = {\n",
    "    'Sale_MF': 'Sale_MF_xgboost_model.json',\n",
    "    'Sale_CC': 'Sale_CC_xgboost_model.json',\n",
    "    'Sale_CL': 'Sale_CL_xgboost_model.json'\n",
    "}\n",
    "\n",
    "regression_model_features =  ['ActBal_CC', 'TransactionsDeb', 'TransactionsCred', 'Count_MF', 'Sex_F',\n",
    "       'VolumeDeb_CA', 'ActBal_MF', 'TransactionsDebCashless_Card',\n",
    "       'VolumeCred_CA', 'VolumeDeb_PaymentOrder', 'ActBal_CL', 'VolumeCred',\n",
    "       'Sex_M', 'TransactionsDeb_CA', 'VolumeDeb']\n",
    "\n",
    "## Order of columns in models trained using xgboost\n",
    "xgboost_column_order = ['ActBal_SA', 'VolumeCred', 'VolumeDebCash_Card', 'VolumeDeb_PaymentOrder', \n",
    "                        'ActBal_CC', 'Count_CC', 'TransactionsDeb', 'ActBal_MF', 'Count_MF', \n",
    "                        'TransactionsDebCashless_Card', 'TransactionsDebCash_Card', 'Count_CL', 'Sex_F', \n",
    "                        'Count_OVD', 'Sex_M', 'TransactionsDeb_PaymentOrder', 'Age', 'ActBal_CL', \n",
    "                        'VolumeDeb', 'VolumeDebCashless_Card', 'ActBal_CA', 'Count_CA', 'Tenure', \n",
    "                        'ActBal_OVD', 'TransactionsCred', 'Count_SA']\n",
    "\n",
    "## target columns for which predictions are to be made\n",
    "target_columns = ['Sale_MF','Sale_CC','Sale_CL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed3b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load pickled files, contains error handling\n",
    "def load_pickle_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)  \n",
    "        return data  \n",
    "    except (pickle.UnpicklingError, EOFError, AttributeError, TypeError):\n",
    "        return False  \n",
    "    except Exception as e:\n",
    "        return False  \n",
    "\n",
    "# Function to save dataframes as csv files, contains error handling\n",
    "def save_csv(folder_to_save, file_name,df_to_save):\n",
    "    if os.path.exists(folder_to_save) and os.path.isdir(folder_to_save) :\n",
    "        df_to_save.to_csv(folder_to_save+'/'+file_name)\n",
    "    else:\n",
    "        print(f\"Error, folder {folder_to_save} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8c90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "data = load_pickle_file(cleaned_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6015cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep those records where no data is available on previous sale\n",
    "cleaned_data_without_labels = data.iloc[np.where((data.Sale_MF+data.Sale_CC+data.Sale_CL)==0)[0],].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a1f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d484c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_revenue(data_without_labels):\n",
    "    # Drop columns which are not required\n",
    "    data_without_labels.drop(columns=cols_to_drop_regression,inplace=True)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    data_encoded = pd.get_dummies(data_without_labels, columns=cat_cols_to_encode)\n",
    "    \n",
    "    # Move 'Client' identifier to index\n",
    "    data_encoded.set_index('Client',inplace=True)\n",
    "    \n",
    "    # Load the scaler\n",
    "    folder_path_target = regression_model_folder_path\n",
    "    file_toopen = 'scaler.pkl'\n",
    "    scaler = load_pickle_file(folder_path_target+file_toopen)\n",
    "\n",
    "    #Encode data\n",
    "    try:\n",
    "        data_encoded[numeric_cols_to_standardize_regression] = scaler.transform(data_encoded[numeric_cols_to_standardize_regression])\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    # Reduce data to contain only features selected for the model\n",
    "    data_selected = data_encoded.loc[:, regression_model_features]\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_pickle_file(regression_model_folder_path+'/best_model.pkl')\n",
    "    \n",
    "    # make predictions\n",
    "    predicted_revenue = model.predict(data_selected)\n",
    "    data_selected['Predicted_revenue'] = predicted_revenue\n",
    "    \n",
    "    # Move 'Client' identifier back to columns\n",
    "    data_selected.reset_index(inplace=True,drop=False)\n",
    "    \n",
    "    # Save as csv file \n",
    "    save_csv(results_folder_path, 'Predicted_Revenue.csv',data_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9074a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_propensity(data_without_labels):\n",
    "    # Drop columns which are not required\n",
    "    data_without_labels.drop(columns=cols_to_drop_classification,inplace=True)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    data_encoded = pd.get_dummies(data_without_labels, columns=cat_cols_to_encode)\n",
    "\n",
    "    for sale_target in target_columns:\n",
    "        data_encoded_target = data_encoded.copy()\n",
    "        # Load the scaler\n",
    "        folder_path_target = classification_model_folder_path+sale_target+\"/\"\n",
    "        file_toopen = 'scaler.pkl'\n",
    "        scaler = load_pickle_file(folder_path_target+file_toopen)\n",
    "\n",
    "        #Encode data\n",
    "        try:\n",
    "            data_encoded_target[numeric_cols_to_standardize_classification] = scaler.transform(data_encoded_target[numeric_cols_to_standardize_classification])\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "        # Load the model\n",
    "        file_toopen = model_selected[sale_target]\n",
    "        try:\n",
    "            loaded_xgb_model = xgb.XGBClassifier()\n",
    "            loaded_xgb_model.load_model(folder_path_target+file_toopen)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "        # Move 'Client' identifier to index\n",
    "        data_encoded_target.set_index('Client',inplace=True)\n",
    "\n",
    "        #Make predictions\n",
    "        Sale_predictions = loaded_xgb_model.predict(data_encoded_target[xgboost_column_order])\n",
    "        Sale_propabilities = loaded_xgb_model.predict_proba(data_encoded_target[xgboost_column_order])\n",
    "        data_encoded_target[sale_target]=Sale_predictions\n",
    "        data_encoded_target[sale_target+'_probability']=Sale_propabilities[:,1]\n",
    "\n",
    "        # Move 'Client' identifier back to columns\n",
    "        data_encoded_target.reset_index(inplace=True,drop=False)\n",
    "\n",
    "        # Save as csv file \n",
    "        save_csv(results_folder_path, 'Propensity_'+sale_target+'.csv',data_encoded_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a9bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for Propensity to buy products\n",
      "Generating predictions of potential revenue\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Generating predictions for Propensity to buy products\")\n",
    "    predict_propensity(cleaned_data_without_labels.copy())\n",
    "    print(\"Generating predictions of potential revenue\")\n",
    "    predict_revenue(cleaned_data_without_labels.copy())\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
